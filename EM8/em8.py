# -*- coding: utf-8 -*-
"""EM8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yxBS2MuzyXCWKzqzLRrP8f0s9uujjbg5
"""

# ===============================
# NLP en textos cl√≠nicos simulados
# ===============================

# 1. Librer√≠as necesarias
import pandas as pd
import re
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from google.colab import files

# 2. Subir archivo CSV
print("üìÇ Sube el archivo CSV (dataset_clinico_simulado_200.csv)")
uploaded = files.upload()

# 3. Cargar dataset
FILE_NAME = list(uploaded.keys())[0]   # toma el nombre del archivo subido
df = pd.read_csv(FILE_NAME)

print("\n‚úÖ Dataset cargado correctamente:")
print(df.head())

# 4. Preprocesamiento b√°sico
def limpiar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r"[^a-z√°√©√≠√≥√∫√º√±0-9\s]", "", texto)
    return texto

df["limpio"] = df["texto_clinico"].astype(str).apply(limpiar_texto)

# 5. Tokenizaci√≥n y lematizaci√≥n con spaCy
nlp = spacy.load("es_core_news_sm")

def tokenizar_y_lematizar(texto):
    doc = nlp(texto)
    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    return tokens

df["tokens"] = df["limpio"].apply(tokenizar_y_lematizar)

# 6. TF-IDF
vectorizer = TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)
X_tfidf = vectorizer.fit_transform(df["tokens"])

# 7. Matriz de similitud coseno
sim_matrix = cosine_similarity(X_tfidf)

# 8. Ejemplo de similitud entre textos
print("\nüîç Similitud entre el primer y segundo texto:")
print(sim_matrix[0, 1])

# 9. Mostrar t√©rminos m√°s relevantes por TF-IDF
def top_terms_tfidf(row_index, top_n=5):
    row = X_tfidf[row_index].toarray().flatten()
    indices = row.argsort()[::-1][:top_n]
    terms = [(vectorizer.get_feature_names_out()[i], row[i]) for i in indices]
    return terms

print("\nüìå T√©rminos m√°s relevantes del primer registro:")
print(top_terms_tfidf(0, top_n=10))

"""NLP en Textos Cl√≠nicos
Proyecto: Similitud y T√©rminos Clave en Notas M√©dicas
 Descripci√≥n

Este proyecto aplica t√©cnicas tradicionales de NLP (Procesamiento de Lenguaje Natural) para analizar textos cl√≠nicos simulados. Se busca:

Preprocesar los textos cl√≠nicos (limpieza, normalizaci√≥n, tokenizaci√≥n, lematizaci√≥n).

Representar los textos con modelos vectoriales como TF-IDF.

Calcular similitud entre textos usando coseno de similitud.

Extraer t√©rminos clave relevantes de cada documento.

El enfoque est√° dise√±ado para datos m√©dicos simulados, pero puede adaptarse a escenarios reales con precauci√≥n y respetando aspectos √©ticos.

 Resultados esperados

Tabla de similitud: muestra qu√© textos cl√≠nicos son m√°s similares entre s√≠.

Palabras clave: t√©rminos m√©dicos m√°s relevantes por nota.

Visualizaciones: mapas de calor y gr√°ficos con distribuci√≥n de t√©rminos.

 Ejemplo de salida

Similitud coseno entre el documento 0 y 1: 0.82

Palabras clave doc 0: ['hipertensi√≥n', 'tratamiento', 'control']

 Reflexi√≥n cr√≠tica

√âtica y sesgos: Los textos cl√≠nicos reales contienen informaci√≥n sensible; este ejemplo usa datos simulados.

Limitaciones: TF-IDF y similitud coseno no capturan sem√°ntica profunda; pueden confundir sin√≥nimos o contextos cl√≠nicos complejos.

Interpretabilidad: El modelo es sencillo y explicable, √∫til para equipos m√©dicos no t√©cnicos.

En este trabajo aplicamos t√©cnicas cl√°sicas de NLP (Procesamiento de Lenguaje Natural) sobre textos cl√≠nicos simulados. Se implementaron pasos de preprocesamiento como limpieza, tokenizaci√≥n, lematizaci√≥n y vectorizaci√≥n con TF-IDF, lo que permiti√≥ transformar el texto en una representaci√≥n num√©rica interpretable por algoritmos de aprendizaje autom√°tico. Posteriormente, se calcularon similitudes de coseno para identificar relaciones entre documentos, adem√°s de la extracci√≥n de t√©rminos clave relevantes.

Los resultados muestran que estas t√©cnicas, aunque b√°sicas frente a modelos modernos como transformers, siguen siendo muy √∫tiles en contextos donde se requiere interpretabilidad y eficiencia computacional, como en el an√°lisis preliminar de reportes m√©dicos. Sin embargo, tambi√©n debemos considerar desaf√≠os importantes:

La √©tica y privacidad de los datos cl√≠nicos, que son altamente sensibles.

La posibilidad de sesgos si los datos no representan adecuadamente la poblaci√≥n real.

La necesidad de modelos m√°s avanzados en escenarios donde se requiera mayor precisi√≥n o comprensi√≥n sem√°ntica profunda.

En conclusi√≥n, este ejercicio demuestra que el NLP tradicional ofrece una base s√≥lida para an√°lisis cl√≠nico automatizado, y que puede ser un punto de partida antes de avanzar hacia modelos m√°s sofisticados de Machine Learning y Deep Learning.
"""